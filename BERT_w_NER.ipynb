{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BzHLnSPT_wkC",
        "outputId": "1b1b2d3a-4240-4559-8506-c43a57363701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets tokenizers seqeval -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "77d39b0069f84e8fa85c47604886196c",
            "6074ee4d1cd24772aa324948012b3bbe",
            "fda4a85f03824b79b065f79aa433e3af",
            "c5ec64abc6a848ccb73de5523fe58690",
            "811b2cc050ba42a484a23a33a11a3f5e",
            "e66f7afa904b41518334585c51f2c5f7",
            "49166a5f3aa349bda282496beee90fdc",
            "2066ef525ab240febce2d564e391972b",
            "1a8bd73c0f51413ab390d664dad4dbf1",
            "f0a35b8f7df349ea9c865307c0aae332",
            "182bc31582d041c383c2bff8040d2b84",
            "184b38d1009c4f379109594836696552",
            "e9d91073230646bb80ba05662ec0bb78",
            "e785ed5c194f454ba9376f3fb8a4a304",
            "ae862335cc6e473bb8fc5233e2eee8f2",
            "7301a97ebc884cf9879f45f9485498b6",
            "a9b5c4868d7748d78ed02641433c58ac",
            "0bb11482a3d145589fa9b9b1c1bda45c",
            "db0bd615852f487eb20a168582705f71",
            "524f4560a52448f0befebe2078d183d6",
            "38e03c4bac4845a9a0bb55d49618ad35",
            "f11f77c9994b4d279c570d05e027ec6a",
            "f96b5d7700d34a31bd8a24b05280d36b",
            "621955b1cf4044ecb80aefc21448891a",
            "49f6bfd552244100bcb55f387a8e645c",
            "ccfc27a78f414e66860d03d50f493121",
            "13ddae14ead0426ab4b556f96119912b",
            "068d91629e184f349d3964ddb7fd04ae",
            "d3f66ee591fa4ef7a0e07219661afcf8",
            "37343f50a1eb48fab2271bcf641a8b64",
            "7846725f35744fbd9b391160963debb8",
            "cbdfec75144a4f929786bc5ef939a2bd",
            "41e50c84b40048daa947c8ea70587272",
            "0bbc40c3dfb449c3b3a4bb5d17e1cf91",
            "588a5a8335744e8e930c9515f3030e5e",
            "48f0e2051f2f4d148bd65a9170bcd8b4",
            "e232a0e0a1574e1dbc809a7ddc5c3c60",
            "fc8ef014637a49fd9c7fbffa6da09279",
            "f3aee7e66ea84f3e8949b6e121ad2325",
            "c740f1485b044c1f9da24d0a55dea3f3",
            "9d543173165d49bdb0679ed55d7d745f",
            "5b99c3b98dda4907b1800635061f5f83",
            "5b21e3c011ff4c5a895b69fa3a6d4b0f",
            "d0cbfcf8f2914107b7196a0dc32cc7ab",
            "02287aad216c4aecaf64576b0d068193",
            "8dd7ed809fda4813a895674b1f078637",
            "e83c9791393543d186436e0f88241ddf",
            "b11e5f7a0054487291896d3fd93f5e83",
            "1106a261123e424490e96142e049f0b0",
            "2ea527298a2f4e9ca2cfec40ee28613f",
            "47504ce49e8940fa92b35f254dcd64bc",
            "4c43d8933eb34f249718f446375a135e",
            "5ac61aedb5ca4f489e111e2087decbe6",
            "047e032ea5d6431593d64c9b2d8925f7",
            "97ebe1f5b85f4b3d9394ef6f5ef66a7c",
            "5203621099254af7900117ee0a637c78",
            "a8f05a61492d4e6cbf85b7043379914d",
            "acd20be5ce59479a92e0eb9eb12aaf22",
            "fdea90171b714adb9f28461b34d15d01",
            "545664536bde4f409241a506f1f6ab79",
            "05bdc6b6afb743deaeb2a9596b449c54",
            "5420bef02ce948939e6b04aca18c1fb0",
            "2f3ebd11dbcb4d7582c86cde222fd929",
            "b998f64055924b8a9cbe06738cab8166",
            "27d2533c0cdd49cca0537bae05b4f4f9",
            "4a4b6becc01d489bb29809672d421233"
          ]
        },
        "collapsed": true,
        "id": "mrpiNhNwbQqg",
        "outputId": "c55e40f6-fe60-49de-a03b-3eaa94a0c84c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77d39b0069f84e8fa85c47604886196c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "184b38d1009c4f379109594836696552",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f96b5d7700d34a31bd8a24b05280d36b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bbc40c3dfb449c3b3a4bb5d17e1cf91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02287aad216c4aecaf64576b0d068193",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5203621099254af7900117ee0a637c78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast, DataCollatorForTokenClassification, AutoModelForTokenClassification\n",
        "\n",
        "conll2003 = datasets.load_dataset(\"conll2003\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dvLcah8wcU4R",
        "outputId": "1a0f2e3d-4e31-44c9-c3ce-932bbd142509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TUvSaNvfdT0w",
        "outputId": "2f5440a4-591d-4229-f5b8-f938f5405236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': (14041, 5), 'validation': (3250, 5), 'test': (3453, 5)}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XAZ3IovrdYba",
        "outputId": "73359ec5-dde3-40cd-e306-03ae299dfdd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "70TgEXj_dYYj",
        "outputId": "9b941f72-a95a-4c8c-f426-b1c8a8df681a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003[\"train\"].features['ner_tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "collapsed": true,
        "id": "f3zErblpdYVr",
        "outputId": "25b449e2-63a6-4152-bd76-13d6d1f1cd54"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003[\"train\"].description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f8f730eac947463eb50bb8863d12f4dd",
            "c0489c1c269b43babe208187f5cf6ac6",
            "8a75120d1be54f47beec7d96afd1e6e9",
            "8c22864e41974f258fed9fd3c4c46741",
            "8c55ff054605443596262e71e5c8b5a9",
            "5f210e44d7c040d3a30939fc5ccecdf0",
            "c4ded19713aa40798630c08bfbee5453",
            "fcdb9629d3a64651bda15d1df3d92088",
            "9db5c957c00d48108bbf1c9190b9a7d7",
            "e8b97106be9742b486db81b24b83aaa0",
            "bf4c13b6f1cc47d981cee6ed4d4af87b",
            "a142da1ecad04b16acf3411656906507",
            "24ce58308b3b455e84366dc45e8dd7c5",
            "17db2fb851634e9ca38db8231c4ba210",
            "c8921a3c95f3464abc970cd12b353bd0",
            "92a9e197edc14d90a433603a0d0b2e29",
            "98c6c696c5294a9c8899edd13808d7dd",
            "72a40f20456f48958860496c03743191",
            "76c782a2bc4c42719adbbdf58a60825a",
            "addf4cf89d324caf88210401545d9150",
            "d7704f84050245f29078fd2ecc44f56b",
            "aa4430bf75394fcba940a6c2f0f7c09a",
            "06384df3c21e43e2b429c6496c85429a",
            "cc35e44ac6194e5690b1eb60e8bac3cc",
            "76a0291ab0e64d7696d88ea7e44a338c",
            "a47e871a85de4651b3ffd7ade40db818",
            "e1c3969680384f2196d826f5b6c0d3e7",
            "244ea12fbf4545c88731a38646f84690",
            "1065b315441d43078dd894a053633c65",
            "4dd6fbb12d5d44b790b7382f099fbb03",
            "567f8628ac094b579b8414563b5af5dc",
            "3c6c63b33a804a359e2e6681ea2d3224",
            "607845d3d8f84c8aa7ce874f41ab5f0d",
            "66fdf34c954049298fe7ef682a7b499d",
            "2da5dee3bb2c4df89ad4108da4e5c465",
            "45fec53d450b4c268aae409ea8f6e2a3",
            "57aa86bdcc9848668275f167583e73a1",
            "4e481580dc2f4ba4b63e8ae6832eef30",
            "b923b88c22824fbab27a9bbb9acaa03e",
            "86244ef0fceb49a6aedebf9d34640fb8",
            "aff8a65af21c475fa52b9be1444e33f7",
            "84e216a72c2b498aa65ab3b40f60767c",
            "71942249452b41df93bc53ee254febf1",
            "34fed5cf15c044078099f20ba1fdef37"
          ]
        },
        "collapsed": true,
        "id": "TIZWNtvSdYSk",
        "outputId": "7aa8c956-0752-4f2f-8d19-2d1c563b0a93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8f730eac947463eb50bb8863d12f4dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a142da1ecad04b16acf3411656906507",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06384df3c21e43e2b429c6496c85429a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66fdf34c954049298fe7ef682a7b499d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o0OymwDadYPx",
        "outputId": "4498c93a-d665-4428-e308-eb1056e4399a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_text = conll2003['train'][0]\n",
        "\n",
        "tokenized_input = tokenizer(example_text['tokens'], is_split_into_words=True)\n",
        "tokenized_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vlu07VUshBxE",
        "outputId": "3d202747-4e9b-42b6-efd7-cd109e81852d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Kr0TAnfZgdq5",
        "outputId": "7ef7c0ad-8237-4dea-d522-7aa1f05277ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_ids = tokenized_input.word_ids()\n",
        "word_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9tKISIFRdYEw",
        "outputId": "1aba0176-3840-40a0-dc35-ca0248d09eb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 12)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(example_text['ner_tags']), len(tokenized_input[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVSSABusjaT1"
      },
      "source": [
        "# Function `tokenize_and_align_labels`\n",
        "\n",
        "1.   Set -100 as the label for these special tokens and the subwords we wish to mask during training\n",
        "2.   Mask the subword representations after the first subword\n",
        "3.   Then we align the labels with the token ids using the strategy we picked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JQKlWqGtdYB7"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(example, label_all_tokens = True):\n",
        "  tokenized_input = tokenizer(example['tokens'], truncation=True, is_split_into_words=True)\n",
        "  labels = []\n",
        "\n",
        "  for i, label in enumerate(example['ner_tags']):\n",
        "    word_ids = tokenized_input.word_ids(batch_index=i)\n",
        "    # word_ids(): return a list mapping of the tokens to their actual word in the initial sentence\n",
        "    # It returns a list indicating the word corresponding to each token\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "      if word_idx is None:\n",
        "        # set -100 as the label for these special tokens\n",
        "        label_ids.append(-100)\n",
        "      elif word_idx != previous_word_idx:\n",
        "        # if current word_idx is != prev then its the most regular case\n",
        "        # and add the corresponding token\n",
        "        label_ids.append(label[word_idx])\n",
        "      else:\n",
        "        # to take care of sub-words which have the same word_idx\n",
        "        # set -100 as well for them, but only if label_all_tokens == False\n",
        "        label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "      previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "  tokenized_input['labels'] = labels\n",
        "  return tokenized_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PYHAw_Lgj25_",
        "outputId": "a4449fc2-5cf9-4de7-bd33-d269b5d5a6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 1860, 112, 188, 4702, 1106, 1103, 1735, 1913, 112, 188, 27431, 3914, 14651, 163, 7635, 4119, 1163, 1113, 9031, 11060, 1431, 4417, 8892, 3263, 2980, 1121, 2182, 1168, 1190, 2855, 1235, 1103, 3812, 5566, 1108, 27830, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
          ]
        }
      ],
      "source": [
        "q = tokenize_and_align_labels(conll2003['train'][4:5])\n",
        "\n",
        "print(q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l9fQhkorjIa"
      },
      "source": [
        "# Before applying the `tokenize_and_align_labels()` the `tokenized_input` has 3 keys\n",
        "*   `input_ids`\n",
        "*   `token_type_ids`\n",
        "*   `attention_mask`\n",
        "\n",
        "But after applying `tokenize_and_align_labels()` we have an extra key - `labels`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5qwFENDcj2dF",
        "outputId": "56f0f81a-31ce-447f-b238-86d02a9a863f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]                                    -100\n",
            "Germany                                  5\n",
            "'                                        0\n",
            "s                                        0\n",
            "representative                           0\n",
            "to                                       0\n",
            "the                                      0\n",
            "European                                 3\n",
            "Union                                    4\n",
            "'                                        0\n",
            "s                                        0\n",
            "veterinary                               0\n",
            "committee                                0\n",
            "Werner                                   1\n",
            "Z                                        2\n",
            "##wing                                   2\n",
            "##mann                                   2\n",
            "said                                     0\n",
            "on                                       0\n",
            "Wednesday                                0\n",
            "consumers                                0\n",
            "should                                   0\n",
            "buy                                      0\n",
            "sheep                                    0\n",
            "##me                                     0\n",
            "##at                                     0\n",
            "from                                     0\n",
            "countries                                0\n",
            "other                                    0\n",
            "than                                     0\n",
            "Britain                                  5\n",
            "until                                    0\n",
            "the                                      0\n",
            "scientific                               0\n",
            "advice                                   0\n",
            "was                                      0\n",
            "clearer                                  0\n",
            ".                                        0\n",
            "[SEP]                                    -100\n"
          ]
        }
      ],
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(q['input_ids'][0]), q['labels'][0]):\n",
        "  print(f\"{token: <40} {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "a4dfdcc72a3b4310be696c2c56770574",
            "bebde800eebb40b0a3f6697f152c36e9",
            "ea748f12672644138f3e55783a1c8971",
            "d7fc99244a4d48c6a6c022484ffb96ee",
            "df3ed84be83f417fac14c2fb4e16de7d",
            "8a1653d045b24d5f9756bd3b2cea730b",
            "7fecd08ba8634d7ca1d46cc18cf2285f",
            "3f4fb060e4e642afa9ac2c828eac2cb3",
            "4af3241d273345738f5c4929042fb0ef",
            "720e8d1208934a6580a26d398f41b051",
            "b5b1e1892ce848ffafd2dc134c63898f",
            "1af6bbe4ea614762abe38866c82c2d9e",
            "3bc77e78529c4c0795be432aa10d0ce6",
            "045a2067e6ae41a4a1f9ecc25d5d78ea",
            "21bd088c2276421683268dc237bbbea2",
            "75bf8deea7af4c738962d8662e9a6710",
            "53f54d35ccbf43dc86a2a2eb25162db3",
            "f62a6ed26432492a98489d51522969e1",
            "484e8c9de85f492cbf88820ed6e1ba97",
            "4b05da481bdf4f65a1bbdebafef17329",
            "e8be2aab59894a19ab5f0899b79f7a87",
            "06724fb46e5e467c979298adb9048b6c",
            "d0943508955141c3afe6d275ef01ed93",
            "b71995f1dc544c21b92f32318d53f9f9",
            "db89341da01440ef8adf32bd2bf43c3b",
            "71b227a3f46a4544942e87a3e7e8e938",
            "c57ba1f2827b47f2ad627f3c3c695702",
            "4956da29438342bdba8344ce389eddcb",
            "ffb7bc725bf147e5ab08fc3d31969c05",
            "293173976d8342faa7102e1b258c392e",
            "8c172d11f3b445e297cc045a91387321",
            "99a1a192e7c4405e825a63782010687a",
            "f6dd163f89ee41ef94e40bf7d95d83a1"
          ]
        },
        "collapsed": true,
        "id": "RBbw9e_TreFJ",
        "outputId": "9c884dee-3fc1-4407-a667-970b246dbf9f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4dfdcc72a3b4310be696c2c56770574",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1af6bbe4ea614762abe38866c82c2d9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0943508955141c3afe6d275ef01ed93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "be8c7a74cb6b4eca9a764004eefe46cd",
            "c7dc7fd126cc4f89bd225ec05c6d2780",
            "7c52464071db45868541e4d98d93648c",
            "097948082ee4421898b06bc7e925ed73",
            "55c5f2f3d75d439c840eced0e57b57ce",
            "3360bd5e21f7472a839b47f64861a35c",
            "e787a85fd980418abacad182b92b2de2",
            "c6b9433d4cec4812b01f6fd3b88329b2",
            "fda78fe616764bae84058548a4c4fa20",
            "11796b42291644c9b46960f1e1ec7218",
            "c434d65cbbbe45eda9b6328c934d9424"
          ]
        },
        "collapsed": true,
        "id": "piFfL3wrrd_s",
        "outputId": "18a0e493-06c3-4266-d354-5fa2121b3734"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be8c7a74cb6b4eca9a764004eefe46cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained('bert-base-cased', num_labels=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I65XRlHdrd8k",
        "outputId": "7ff55eb7-ae5c-4c63-e7a1-c9fb8fc96cb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"test-ner\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5XvhBmdZuAH1"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3O4afa_pwggl",
        "outputId": "3aa0b8ec-9ec1-4252-b44f-0eea038675e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install evaluate -q # Install the evaluate package which contains load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "P1QT-IKYwzIy"
      },
      "outputs": [],
      "source": [
        "import evaluate  # Import load_metric from evaluate instead of datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8d5d211043674ea397f9119d64d9bf04",
            "3927d9a43cbe4a428192e23b6ff9d34f",
            "01f87accf255495c9c83c1232702a7ca",
            "37d504b79c824de6aafb6c784e3ddad7",
            "2a74d698952d49cbad2c5aee102d56ad",
            "4e679cdb420f49308129839d16915b3f",
            "cc8fd2b3aea94319b3a08539a24467c1",
            "7883c3a36b3e42f5ad30aaf6cd0960c9",
            "76446adb8d714196a73b9325bf6724ef",
            "5372abe3ad124e3f9e419022eac3337e",
            "b525994dc68246e9acd5f02589a3f884"
          ]
        },
        "collapsed": true,
        "id": "gZIkJoxyrd48",
        "outputId": "b1c11f8d-37b2-4401-8f09-e80574f51227"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d5d211043674ea397f9119d64d9bf04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric = evaluate.load('seqeval')\n",
        "\n",
        "example = conll2003['train'][0]\n",
        "\n",
        "label_list = conll2003['train'].features['ner_tags'].feature.names\n",
        "\n",
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5vuVtqDCj2Zc",
        "outputId": "dc83a898-6e25-4c14-92a3-b44e9f26c59c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = [label_list[i] for i in example['ner_tags']]\n",
        "\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dDVQKKp_j2QH",
        "outputId": "29edff75-0cc3-4547-ad51-442af097cf5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'MISC': {'precision': np.float64(1.0),\n",
              "  'recall': np.float64(1.0),\n",
              "  'f1': np.float64(1.0),\n",
              "  'number': np.int64(2)},\n",
              " 'ORG': {'precision': np.float64(1.0),\n",
              "  'recall': np.float64(1.0),\n",
              "  'f1': np.float64(1.0),\n",
              "  'number': np.int64(1)},\n",
              " 'overall_precision': np.float64(1.0),\n",
              " 'overall_recall': np.float64(1.0),\n",
              " 'overall_f1': np.float64(1.0),\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=[labels], references=[labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xOnhFwM50-lB"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "  pred_logits, labels = eval_preds\n",
        "  pred_logits = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "  prediction = [\n",
        "      [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] for prediction, label in zip(pred_logits, labels)\n",
        "  ]\n",
        "  true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100] for prediction, label in zip(pred_logits, labels)\n",
        "  ]\n",
        "  results = metric.compute(predictions=prediction, references=true_labels)\n",
        "\n",
        "  return {\n",
        "      'precision': results['overall_precision'],\n",
        "      'recall': results['overall_recall'],\n",
        "      'f1': results['overall_f1'],\n",
        "      'accuracy': results['overall_accuracy']\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7NJn_hK30-ia",
        "outputId": "68c74577-fd4c-449c-bbc4-6e2d30a7a566"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-5b1a4489fcf1>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "collapsed": true,
        "id": "7_-y4zBx0-fz",
        "outputId": "a69c16fa-210c-463c-ac74-d000dd7b481a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2634/2634 11:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.045900</td>\n",
              "      <td>0.066414</td>\n",
              "      <td>0.929781</td>\n",
              "      <td>0.936121</td>\n",
              "      <td>0.932940</td>\n",
              "      <td>0.983605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>0.067507</td>\n",
              "      <td>0.939467</td>\n",
              "      <td>0.942670</td>\n",
              "      <td>0.941066</td>\n",
              "      <td>0.985195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.066049</td>\n",
              "      <td>0.942007</td>\n",
              "      <td>0.945810</td>\n",
              "      <td>0.943905</td>\n",
              "      <td>0.985798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()\n",
        "\n",
        "model.save_pretrained('ner_model')\n",
        "\n",
        "tokenizer.save_pretrained('tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iCsroZQ24esf"
      },
      "outputs": [],
      "source": [
        "id2label = {\n",
        "    str(i) : label for i, label in enumerate(label_list)\n",
        "}\n",
        "\n",
        "label2id = {\n",
        "    label: str(i) for i, label in enumerate(label_list)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_0lAxESG4ep8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "config = json.load(open('ner_model/config.json'))\n",
        "config['id2label'] = id2label\n",
        "config['label2id'] = label2id\n",
        "\n",
        "json.dump(config, open('ner_model/config.json', 'w'))\n",
        "\n",
        "model_fine_tuned = AutoModelForTokenClassification.from_pretrained('ner_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3rqybao-VJJ"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "O3sn8g9u0-aY"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EiQyMlZb5Wtk",
        "outputId": "ebf77022-0def-4891-c6f3-9261c62df837"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'entity': 'B-PER', 'score': np.float32(0.99896395), 'index': 1, 'word': 'Bill', 'start': 0, 'end': 4}, {'entity': 'I-PER', 'score': np.float32(0.99889576), 'index': 2, 'word': 'Gates', 'start': 5, 'end': 10}, {'entity': 'B-ORG', 'score': np.float32(0.9965133), 'index': 7, 'word': 'Microsoft', 'start': 29, 'end': 38}]\n"
          ]
        }
      ],
      "source": [
        "nlp = pipeline('ner', model=model_fine_tuned, tokenizer=tokenizer)\n",
        "example = \"Bill Gates is the Founder of Microsoft\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm5mimxRnX6J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
  },
  "nbformat": 4,
  "nbformat_minor": 0
}